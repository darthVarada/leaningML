{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWfDNrm4JPj"
      },
      "source": [
        "## 00. pythorch fundamentals\n",
        "\n",
        "Resource notebook: https://www.learnpytorch.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b95Wd9J_MBCm",
        "outputId": "c72acdde-9834-443d-a40e-117612cfe319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.0+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKs87ObK5leM"
      },
      "source": [
        "## introduction to Tensor\n",
        "\n",
        "##creating tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1xqQBrGMGOO",
        "outputId": "868d6361-37a7-459a-88bf-d483d1831bee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scaler\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5lc7OUF6Bvl",
        "outputId": "96a7b7ad-bfe7-4674-e87d-3a7a2ee380ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww6wyzxw7n6P",
        "outputId": "cfb9e619-8ee0-4a06-af95-b64bf907f2d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtf9D7bB7w6Q",
        "outputId": "bcce8d4b-2da3-41b5-93b4-e2be661fb4bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#VECTOR\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B6KNoWi76Db",
        "outputId": "0bd65936-07b3-4291-aca2-e95e5c872a18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVzdxbMm8PQE",
        "outputId": "16221d99-8ff0-4de7-8e4d-8a27595f0ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houw4GAg8d7f",
        "outputId": "8cb74b1d-78c5-4876-e483-bd5fc20f326a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                      [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGYiTAfi8v1y",
        "outputId": "a582e19a-3a43-4160-d0a8-b5247aa83151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_IjFopf9HXA",
        "outputId": "ff6294a0-18ce-4e6b-80eb-00894e38faf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sIvGuzld9Lxe"
      },
      "outputs": [],
      "source": [
        "TENSOR = torch.tensor([[[1, 3, 6],\n",
        "                       [7, 3, 2],\n",
        "                       [3, 0, 4]],\n",
        "                       [[5, 4, 6],\n",
        "                        [6, 4, 9],\n",
        "                        [4, 4, 4]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUx5NrBuBmr9",
        "outputId": "1eafb05a-31e2-40ca-a18f-1566a820f1ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37vJZTgcBp2s",
        "outputId": "219f2fa1-dfe9-453a-8849-fbcc74131d7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Kb7dzXyAAq"
      },
      "source": [
        "### Random tensors\n",
        "\n",
        "Por que tensores randomicos?\n",
        "Ã© o melhor jeito de amplificar uma rede neural.\n",
        "Se comeca uma rede com seus tensores randomicos, depois\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jD7sESO7yIrC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6753, 0.7574, 0.6176, 0.2695],\n",
              "        [0.5249, 0.5818, 0.3401, 0.5643],\n",
              "        [0.8287, 0.8834, 0.8997, 0.7812]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 224, 224]), 3)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#criando um tensor de dimensoes similares para imagens\n",
        "random_image_size_tensor =  torch.rand(size=(3, 224, 224)) #hight, width, colour channels (R, G, B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### zeros and ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a tensor of all zeros\n",
        "zeros = torch.zeros(size =(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros * random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a tensor with all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_to_ten = torch.arange(start=1 , end= 11,step=1)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor Datatype\n",
        "\n",
        "NOTE: tensor datatypes is one of the 3 big erros you`ll run into with PyThorch & deep learning:\n",
        "\n",
        "    1. Tensors not right datatype\n",
        "    2. Tensors not right shape\n",
        "    3. Tensors not on the right device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fafap\\AppData\\Local\\Temp\\ipykernel_34828\\3379230706.py:2: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  float_32_tensor = torch.tensor([3.54548415, 6.05421874, 9.0548451215],\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.54548415, 6.05421874, 9.0548451215],\n",
        "                                 dtype=torch.int32, #what data type is the tensor (e.g. float32 or float16)\n",
        "                                 device= None, #what divices is your tensor on like cuda\n",
        "                                 requires_grad= False) #whether or not to track gradients with this tensors operations\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float16)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor * float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ten_zeros.is_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### getting information from tensors  (tensor attributes)\n",
        "\n",
        "    1. Tensors not right datatype - to get datatype from a tensor, can use `tensor.dtype`\n",
        "    2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "    3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5832, 0.1716, 0.9896, 0.6924],\n",
              "        [0.9332, 0.5969, 0.6488, 0.1037],\n",
              "        [0.6804, 0.2720, 0.9878, 0.2834]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5832, 0.1716, 0.9896, 0.6924],\n",
            "        [0.9332, 0.5969, 0.6488, 0.1037],\n",
            "        [0.6804, 0.2720, 0.9878, 0.2834]])\n",
            "data type of the tensor is torch.float32\n",
            "shape of the tensor is torch.Size([3, 4])\n",
            "divice of the tensor is cpu\n"
          ]
        }
      ],
      "source": [
        "#find out some details about some tensor\n",
        "print(some_tensor)\n",
        "print(f\"data type of the tensor is {some_tensor.dtype}\")\n",
        "print(f\"shape of the tensor is {some_tensor.shape}\")\n",
        "print(f\"divice of the tensor is {some_tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipulating Tensors (tensors operations)\n",
        "\n",
        "Tensors operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a tensor\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# multiply tensor by 10\n",
        "tensor * 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtract tensor by 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try out pyTorch in-build functions\n",
        "torch.mul(tensor, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrix multiplication \n",
        "\n",
        "two main ways of performing muiltiplication in neural networks and deep leraning:\n",
        "\n",
        "1. element-wise multiplication\n",
        "2. Matrix multiplication\n",
        " more information on: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "there are two main rules that performing matrix multiplication needs to satisfy:\n",
        "1. the **inner dimations** must match:\n",
        "* ` (3, 2) @ (3, 2)` wont work\n",
        "* ` (2, 3) @ (3, 2)` will work\n",
        "* ` (3, 2) @ (2, 3)` will work\n",
        "2. the resulting matrix has the shape of the **outer dimensions**:\n",
        "* ` (2, 3) @ (3, 2)` -> `(2, 2)`\n",
        "* ` (3, 2) @ (2, 3)` -> `(3, 3)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4538, 0.8553, 0.7276],\n",
              "        [0.5592, 0.9503, 0.7746],\n",
              "        [0.3173, 0.4910, 0.3827]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#this wont work for exemple\n",
        "#torch.matmul(torch.rand(3, 2), torch.rand(3, 2))\n",
        "# the resulting matrix has the shape of the **outer dimensions**\n",
        "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equal: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# element-wise multiplication\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f\"Equal: {tensor*tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the same thing by hand is like\n",
        "1*1 + 2*2 + 3*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14)\n",
            "CPU times: total: 0 ns\n",
            "Wall time: 3.99 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One of the most common erros in deep leaning: shape errors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "Tensor_A = torch.tensor([[1, 2],\n",
        "                        [3, 4],\n",
        "                        [5, 6]])\n",
        "Tensor_B = torch.tensor([[7, 8],\n",
        "                        [9, 10],\n",
        "                        [11, 12]]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "#gets a error becouse thoes not follow the rule fo Mul matrix\n",
        "#torch.mm(Tensor_A, Tensor_B)  the same thing for writing torch.matmul()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " To fix our tensor shape issues, we can  manipulate the shape of our tensor using a **transpose**\n",
        "\n",
        " A **tranpose** switches the axes or dimansions of a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Tensor_B "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7,  9, 11],\n",
              "         [ 8, 10, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Tensor_B.T, Tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: Tensor_A = torch.Size([3, 2]), Tensor_B = torch.Size([3, 2])\n",
            "new shapes: Tensor_A = torch.Size([3, 2]),(same shape as above) Tensor_B = torch.Size([2, 3])\n",
            "Multiplying: torch.Size([3, 2]) @ torch.Size([3, 2]) -> inner dimansions must match\n",
            "Output:\n",
            "\n",
            "tensor([[ 23,  29,  35],\n",
            "        [ 53,  67,  81],\n",
            "        [ 83, 105, 127]])\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[ 23,  29,  35],\n",
              "         [ 53,  67,  81],\n",
              "         [ 83, 105, 127]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the matrix multplication operation works when Tensor_B is transpose\n",
        "print(f\"Original shape: Tensor_A = {Tensor_A.shape}, Tensor_B = {Tensor_B.shape}\")\n",
        "print(f\"new shapes: Tensor_A = {Tensor_A.shape},(same shape as above) Tensor_B = {Tensor_B.T.shape}\")\n",
        "print(f\"Multiplying: {Tensor_A.shape} @ {Tensor_B.shape} -> inner dimansions must match\")\n",
        "print(f\"Output:\\n\")\n",
        "Output = torch.mm(Tensor_A, Tensor_B.T)\n",
        "print(Output)\n",
        "print(f\"Output shape: {Output.shape}\")\n",
        "\n",
        "torch.mm(Tensor_A, Tensor_B.T), torch.mm(Tensor_A, Tensor_B.T).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding the min, max, mean, sum, etc(tensor aggregetion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create tensors\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#find the min\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the mean note: the torch.mean() function requeires a tensor of float32 datatype to work\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### finding the positional min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "x += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the position in tensor that has the minimum value with argmin() -> returns index position of target tensor where the minimum value occurrs\n",
        "x.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezsing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certing shape but keep the same memory\n",
        "as the original \n",
        "* Stacking - combine multiples tensors on top of each other (vstack) or side by side\n",
        "(hstack) \n",
        "* Squeeze - removes all `1` demensions from a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adds an extra dimension\n",
        "x_reshaped = x.reshape(1, 9)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([9., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([[9., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# changing z changes x (becouse a view of a tensor shares the same memoryas the original input)\n",
        "z[:, 0] = 9\n",
        "x, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[9., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [9., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [9., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [9., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim = 0)\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([9., 2., 3., 4., 5., 6., 7., 8., 9., 9., 2., 3., 4., 5., 6., 7., 8., 9.,\n",
              "        9., 2., 3., 4., 5., 6., 7., 8., 9., 9., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hstack view the horizontal witch means that dim = 1\n",
        "x_stacked = torch.hstack([x, x, x, x])\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[9., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([9., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# remove extra demensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous target: tensor([9., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[9.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "new shape: torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim (dimension)\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# add a extra dimention with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1) #can change to dim=1 to see what happens\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"new shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224,224,3)) #[height, width, colour_channels]\n",
        "\n",
        "#permute the original tensor to rearrange the axis (or dem) order\n",
        "x_permuted = x_original.permute(2, 0, 1) #s shift eaxis 0 -> 1, 1 -> 2, 2 -> 0\n",
        "print(f\"previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\") # [colour_channels, hight, width]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(45346.), tensor(45346.))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original[0, 0, 0] = 45346\n",
        "x_original[0, 0, 0], x_permuted[0, 0, 0] #will be the same becouse they share the same memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "indexing with pyTorch is similar to indexing with numPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# index on our new tensor\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor(1)\n",
            "tensor(9)\n"
          ]
        }
      ],
      "source": [
        "print(x[0, 0]) # just the middle part, can also write x[0][0][0]\n",
        "print(x[0, 0, 0]) #just the firt number, can also write x[0][0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 3])\n",
            "tensor([1, 2])\n"
          ]
        }
      ],
      "source": [
        "# can also use \":\" to select \"all\" of the target dimesion\n",
        "print(x[0, 0, 1:]) # you can read this like select 1>= \n",
        "print(x[0, 0, :2]) # can also read this as select 2 <="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all the elements from the frist and second dimensions but only index 1 of 2nd dimension\n",
        "x[:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9)\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ],
      "source": [
        "#index to reaturn 9\n",
        "print(x[0][2][2]) # last number also 9\n",
        "\n",
        "#index to return 3,6,9\n",
        "print(x[:,:,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch tensors & NumPy\n",
        "\n",
        "numPy is a popular scientific python numerical computing library\n",
        "\n",
        "and because of this, pytorch has functionality to interact with it\n",
        "\n",
        "* data in NumPy, want in pyTorch tensor -> `torch.from_numpy(ndarry)`\n",
        "* PyTroch tensor -> NumPy -> `torch.Tensor.numpy()` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numpy arroy to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array) #warning: when converting from numpy -> pytorch, pytorch reflects numpy`s default datatype of float64 unless specifield otherwise \".type(torch.float32)\"\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the value of array, will keep theis to the tensor?\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tensor to numpy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor , numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
              " tensor([2., 2., 2., 2., 2., 2., 2.]))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#change the tensor, will reflects to numpy tensor?\n",
        "\n",
        "tensor = tensor + 1\n",
        "numpy_tensor, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## reproducbility (trying to take the random out of random)\n",
        "\n",
        "in short how a neural network learns:\n",
        "\n",
        "`starts with random numbers -> tensor operations -> update random numbers to try and make`\n",
        "`they bettter representations of the data -> again -> again -> again...`\n",
        "\n",
        "to reduce the randomness in neural networks and pytorch comes the concept fo **random seed**\n",
        "\n",
        "Essentially what the random seed works is \"flavour\" the randomness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3078, 0.6585, 0.2221, 0.4092],\n",
            "        [0.3125, 0.7066, 0.9661, 0.8152],\n",
            "        [0.3557, 0.5672, 0.2842, 0.4304]])\n",
            "tensor([[0.9195, 0.6745, 0.0994, 0.7964],\n",
            "        [0.8904, 0.2058, 0.1266, 0.0750],\n",
            "        [0.5422, 0.2870, 0.7395, 0.3400]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# create two random tensors\n",
        "Random_Tensor_A = torch.rand(3, 4)\n",
        "Random_Tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(Random_Tensor_A)\n",
        "print(Random_Tensor_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and make faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + Nvidea hardware + pytorch working behind the scenes to make everything hunky dory (good)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. getting a GPU\n",
        "\n",
        "1. Easiest - use Goggle colab for a free GPU (options to upgrade as well)\n",
        "2. Use your own GPU - a little bit of setup and requires the investment of purchusing a GPU, there`s lots of options "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "\n",
        "# FunÃ§Ã£o para criar um objeto 'args' com base nos argumentos passados\n",
        "def create_args(disable_cuda):\n",
        "    args = argparse.Namespace()\n",
        "    args.disable_cuda = disable_cuda\n",
        "    args.device = None\n",
        "    if not args.disable_cuda and torch.cuda.is_available():\n",
        "        args.device = torch.device('cuda')\n",
        "    else:\n",
        "        args.device = torch.device('cpu')\n",
        "    return args\n",
        "\n",
        "# Passando o argumento 'disable_cuda' como False (usar GPU) ou True (usar CPU)\n",
        "disable_cuda = False  # Defina como True ou False para habilitar ou desabilitar a GPU\n",
        "args = create_args(disable_cuda)\n",
        "print(args.device)  # Aqui vocÃª verÃ¡ se estÃ¡ usando a GPU ou a CPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU sendo usada\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
